{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "widespread-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "royal-feedback",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.17570497 0.81667436 0.81373083 0.45365642]\n",
      " [0.65507156 0.9182954  0.44150857 0.9319078 ]\n",
      " [0.46075487 0.61216577 0.08352444 0.43859082]\n",
      " [0.20147648 0.34532974 0.41958065 0.19458197]\n",
      " [0.80030846 0.79636807 0.5785543  0.60433818]\n",
      " [0.39232041 0.16670067 0.46795182 0.64587489]\n",
      " [0.37149397 0.38602793 0.57724609 0.77117301]\n",
      " [0.44276678 0.61618945 0.08221358 0.92478675]\n",
      " [0.72859033 0.41533477 0.68552604 0.87852771]\n",
      " [0.53891444 0.30762412 0.18869989 0.34281981]]\n",
      "tf.Tensor([1 3 1 2 0 3 3 3 3 0], shape=(10,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]], shape=(10, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "goal_size = 4\n",
    "batch_size = 10\n",
    "example_goal = np.random.rand(batch_size, goal_size)\n",
    "np.random.shuffle(example_goal)\n",
    "print(example_goal)\n",
    "arg_max = tf.argmax(example_goal, axis=1, output_type=tf.int32)\n",
    "print(arg_max)\n",
    "one_hot = tf.one_hot(arg_max, depth=1)\n",
    "print(one_hot)\n",
    "# # example_goal[0][0] = 1\n",
    "\n",
    "# np.random.shuffle(example_goal)\n",
    "# print(example_goal, '\\n', tf.argmax(example_goal))\n",
    "\n",
    "# # np.random.shuffle(example_goal)\n",
    "# example_goal = tf.convert_to_tensor(example_goal)\n",
    "# print(tf.argmax(example_goal, 1), tf.reduce_max(example_goal))\n",
    "# highest_vals_per_col = tf.argmax(example_goal, 1)\n",
    "# print(highest_vals_per_col, highest_vals_per_col.shape)\n",
    "\n",
    "# # max_value = max(example_goal)\n",
    "# # max_index = my_list.index(max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "spare-sally",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Reduction axis 0 is empty in shape [0] [Op:ArgMax]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-81a9f50731fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#     place_h[i] = [example_goal[0][a]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mone_hot_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplace_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mone_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_goal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moff_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlvenv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlvenv/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36margmax_v2\u001b[0;34m(input, axis, output_type, name)\u001b[0m\n\u001b[1;32m    303\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlvenv/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36marg_max\u001b[0;34m(input, dimension, output_type, name)\u001b[0m\n\u001b[1;32m    819\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m       return arg_max_eager_fallback(\n\u001b[0m\u001b[1;32m    822\u001b[0m           input, dimension, output_type=output_type, name=name, ctx=_ctx)\n\u001b[1;32m    823\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlvenv/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36marg_max_eager_fallback\u001b[0;34m(input, dimension, output_type, name, ctx)\u001b[0m\n\u001b[1;32m    852\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tidx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_Tidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m   _result = _execute.execute(b\"ArgMax\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0m\u001b[1;32m    855\u001b[0m                              ctx=ctx, name=name)\n\u001b[1;32m    856\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlvenv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Reduction axis 0 is empty in shape [0] [Op:ArgMax]"
     ]
    }
   ],
   "source": [
    "place_h = []\n",
    "# for i in range(goal_size):\n",
    "#     print(i, example_goal.shape)\n",
    "#     a = highest_vals_per_col.data[i]\n",
    "#     print[a]\n",
    "#     place_h[i] = [example_goal[0][a]]\n",
    "    \n",
    "one_hot_idx = tf.argmax(place_h)\n",
    "print(one_hot_idx)\n",
    "one_hot = tf.one_hot(tf.argmax(example_goal), depth=4, dtype=float, on_value=1.0, off_value=0.0)\n",
    "print(one_hot)\n",
    "one_hot = tf.squeeze(one_hot)\n",
    "print(one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "faced-zimbabwe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289\n",
      "[[1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]] \n",
      " 3\n",
      "17 0 17 0\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]] \n",
      " (24, 24)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-5038fc32548b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_up\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_down\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpad_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_right\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpadded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnfz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnfz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnfz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "x,y = 17,17\n",
    "a = np.ones((7,7))\n",
    "# a[1][1] = 1\n",
    "map_ = np.zeros((18,18))\n",
    "\n",
    "\n",
    "\n",
    "shape_total = map_.shape\n",
    "shape_loc = a.shape\n",
    "np.random.shuffle(a)\n",
    "nfz = int((shape_loc[0]-1)/2)\n",
    "print(a, \"\\n\", nfz)\n",
    "\n",
    "pad_left = x\n",
    "pad_right = shape_total[0] - x -1# - shape_loc[0] + nfz\n",
    "pad_up = y # - nfz\n",
    "pad_down = shape_total[0] - y - 1# - shape_loc[0] + nfz\n",
    "\n",
    "print(pad_left, pad_right, pad_up, pad_down)\n",
    "\n",
    "padded = np.pad(a, ((pad_up, pad_down), (pad_left, pad_right)))\n",
    "print(padded, \"\\n\", padded.shape)\n",
    "padded = padded[nfz:(padded.shape[0]-nfz), nfz:(padded[1]-nfz)]\n",
    "print(padded, padded.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "republican-thumb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10)\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] \n",
      " (19, 19)\n"
     ]
    }
   ],
   "source": [
    "# def pad_centered(state, map_in, pad_value):\n",
    "map_in = np.zeros((10,10))\n",
    "print(map_in.shape)\n",
    "padding_rows = math.ceil(map_in.shape[0] / 2.0)\n",
    "padding_cols = math.ceil(map_in.shape[1] / 2.0)\n",
    "position_x, position_y = 0,0\n",
    "map_in[position_x][position_y] = 1\n",
    "pad_value = 1\n",
    "# print(\"pos\", position_x, position_y)\n",
    "position_row_offset = padding_rows - position_y\n",
    "position_col_offset = padding_cols - position_x\n",
    "res = np.pad(map_in,\n",
    "              pad_width=[[padding_rows + position_row_offset - 1, padding_rows - position_row_offset],\n",
    "                         [padding_cols + position_col_offset - 1, padding_cols - position_col_offset],\n",
    "#                          [0, 0]\n",
    "                        ],\n",
    "                  mode='constant',\n",
    "                  constant_values=pad_value)\n",
    "\n",
    "print(res,\"\\n\", res.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "south-arena",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]] \n",
      " True\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]] \n",
      " [[1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros((6,6))\n",
    "b = np.zeros((6,6))\n",
    "\n",
    "for i in range(5):\n",
    "    a[i][i]=1\n",
    "np.random.shuffle(a)\n",
    "b[0][0]=1\n",
    "print(a, \"\\n\", bool(b.any))\n",
    "# a = not bool(a)\n",
    "\n",
    "a = np.ones((6,6))\n",
    "a = np.logical_not(a).astype(int)\n",
    "b = b.astype(int)\n",
    "print(a, \"\\n\", b)\n",
    "\n",
    "c = b*a\n",
    "print(c)\n",
    "# c = np.logical_not(c).astype(int)\n",
    "print(c)\n",
    "print(not np.all(c == 0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "subtle-jewelry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289\n",
      "81\n",
      "208\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "lm_size = (17,17)\n",
    "NT_size = (9,9)\n",
    "\n",
    "print(17**2)\n",
    "print(9**2)\n",
    "print(17**2-9**2)\n",
    "a = np.zeros(lm_size)\n",
    "print(a)\n",
    "\n",
    "\n",
    "\n",
    "# NT_size[0]:(lm_size[0]-NT_size[0]), NT_size[0]:(lm_size[0]-NT_size[0])\n",
    "\n",
    "a[9-5:17-4,9-5:17-4] = 1\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "varying-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [10.3, 22.3, 1.1, 2.34, 0]\n",
    "l2 = [1.3, 2.3, 10.1, 20.34, 330]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "received-printing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False  True]] (32, 32)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def pad_lm_to_total_size(h_target, position):\n",
    "    \"\"\"\n",
    "    pads input of shape local_map to output of total_map_size\n",
    "    \"\"\"\n",
    "\n",
    "    shape_map = (32,32)\n",
    "    shape_htarget = h_target.shape\n",
    "    # print(shape_htarget, shape_map)\n",
    "\n",
    "    x, y = position\n",
    "\n",
    "    pad_left = x\n",
    "    pad_right = shape_map[0] - x - 1\n",
    "    pad_up = y\n",
    "    pad_down = shape_map[1] - y - 1\n",
    "\n",
    "    padded = np.pad(h_target, ((pad_up, pad_down), (pad_left, pad_right)))\n",
    "\n",
    "    lm_as_tm_size = padded[int((shape_htarget[0] - 1) / 2):int(padded.shape[0] - (shape_htarget[0] - 1) / 2),\n",
    "                    int((shape_htarget[1] - 1) / 2):int(padded.shape[1] - (shape_htarget[1] - 1) / 2)]\n",
    "\n",
    "    return lm_as_tm_size.astype(bool)\n",
    "\n",
    "position = (31,31)\n",
    "h_target = np.zeros((15,15))\n",
    "h_target[7][7] = 1\n",
    "\n",
    "pht = pad_lm_to_total_size(h_target, position)\n",
    "print(pht, pht.shape)\n",
    "\n",
    "print(pht.any()==True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "physical-clark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros((10,5))\n",
    "\n",
    "a[9,3]=1\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "excess-wagon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros((10,10))\n",
    "a[0,1]=1\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input \n",
    "input_img = Input(shape=(128, 128, 3))#Encoder \n",
    "y = Conv2D(32, (3, 3), padding='same',strides =(2,2))(input_img)\n",
    "y = LeakyReLU()(y)\n",
    "y = Conv2D(64, (3, 3), padding='same',strides =(2,2))(y)\n",
    "y = LeakyReLU()(y)\n",
    "y1 = Conv2D(128, (3, 3), padding='same',strides =(2,2))(y) # skip-1\n",
    "y = LeakyReLU()(y1)\n",
    "y = Conv2D(256, (3, 3), padding='same',strides =(2,2))(y)\n",
    "y = LeakyReLU()(y)\n",
    "y2 = Conv2D(256, (3, 3), padding='same',strides =(2,2))(y)# skip-2\n",
    "y = LeakyReLU()(y2)\n",
    "y = Conv2D(512, (3, 3), padding='same',strides =(2,2))(y)\n",
    "y = LeakyReLU()(y)\n",
    "y = Conv2D(1024, (3, 3), padding='same',strides =(2,2))(y)\n",
    "y = LeakyReLU()(y)#Flattening for the bottleneck\n",
    "vol = y.shape\n",
    "x = Flatten()(y)\n",
    "latent = Dense(128, activation='relu')(x) \n",
    "\n",
    "\n",
    "# Helper function to apply activation and batch normalization to the # output added with output of residual connection from the encoderdef lrelu_bn(inputs):\n",
    "   lrelu = LeakyReLU()(inputs)\n",
    "   bn = BatchNormalization()(lrelu)\n",
    "   return bn#Decoder\n",
    "y = Dense(np.prod(vol[1:]), activation='relu')(latent)\n",
    "y = Reshape((vol[1], vol[2], vol[3]))(y)\n",
    "y = Conv2DTranspose(1024, (3,3), padding='same')(y)\n",
    "y = LeakyReLU()(y)\n",
    "y = Conv2DTranspose(512, (3,3), padding='same',strides=(2,2))(y)\n",
    "y = LeakyReLU()(y)\n",
    "y = Conv2DTranspose(256, (3,3), padding='same',strides=(2,2))(y)\n",
    "y= Add()([y2, y]) # second skip connection added here\n",
    "y = lrelu_bn(y)\n",
    "y = Conv2DTranspose(256, (3,3), padding='same',strides=(2,2))(y)\n",
    "y = LeakyReLU()(y)\n",
    "y = Conv2DTranspose(128, (3,3), padding='same',strides=(2,2))(y)\n",
    "y= Add()([y1, y]) # first skip connection added here\n",
    "y = lrelu_bn(y)\n",
    "y = Conv2DTranspose(64, (3,3), padding='same',strides=(2,2))(y)\n",
    "y = LeakyReLU()(y)\n",
    "y = Conv2DTranspose(32, (3,3), padding='same',strides=(2,2))(y)\n",
    "y = LeakyReLU()(y)\n",
    "y = Conv2DTranspose(3, (3,3), activation='sigmoid', padding='same',strides=(2,2))(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7cb95fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1296) (None, 1296)\n",
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_157 (InputLayer)          [(None, 1, 17, 17, 4 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_158 (InputLayer)          [(None, 1, 21, 21, 4 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hl_model_local_conv_1 (Conv2D)  (None, 1, 15, 15, 4) 148         input_157[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hl_model_global_conv_1 (Conv2D) (None, 1, 17, 17, 4) 404         input_158[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hl_model_local_conv_2 (Conv2D)  (None, 1, 13, 13, 8) 296         hl_model_local_conv_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "hl_model_global_map_2 (Conv2D)  (None, 1, 13, 13, 8) 808         hl_model_global_conv_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "hl_model_local_conv_3 (Conv2D)  (None, 1, 11, 11, 16 1168        hl_model_local_conv_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "hl_model_global_map_3 (Conv2D)  (None, 1, 9, 9, 16)  3216        hl_model_global_map_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "hl_model_local_conv_4 (Conv2D)  (None, 1, 9, 9, 16)  2320        hl_model_local_conv_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "hl_model_global_flatten (Flatte (None, 1296)         0           hl_model_global_map_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "hl_model_local_flatten (Flatten (None, 1296)         0           hl_model_local_conv_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "hl_model_concat_flatten (Concat (None, 2592)         0           hl_model_global_flatten[0][0]    \n",
      "                                                                 hl_model_local_flatten[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "input_159 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hl_model_concat (Concatenate)   (None, 2593)         0           hl_model_concat_flatten[0][0]    \n",
      "                                                                 input_159[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hl_model_last_dense_layer_hl (D (None, 300)          778200      hl_model_concat[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "hl_model_last_dense_layer (Resh (None, 5, 5, 12)     0           hl_model_last_dense_layer_hl[0][0\n",
      "__________________________________________________________________________________________________\n",
      "hl_model_deconv_1 (Conv2DTransp (None, 9, 9, 16)     4816        hl_model_last_dense_layer[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_32 (TFOpLa (None, 9, 9, 16)     0           hl_model_local_conv_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "hl_model_1st_skip_connection_co (None, 9, 9, 32)     0           hl_model_deconv_1[0][0]          \n",
      "                                                                 tf.compat.v1.squeeze_32[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "hl_model_deconv_2 (Conv2DTransp (None, 11, 11, 8)    2312        hl_model_1st_skip_connection_conc\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_33 (TFOpLa (None, 11, 11, 16)   0           hl_model_local_conv_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "hl_model_2nd_skip_connection_co (None, 11, 11, 24)   0           hl_model_deconv_2[0][0]          \n",
      "                                                                 tf.compat.v1.squeeze_33[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "hl_model_deconv_2.1 (Conv2DTran (None, 13, 13, 8)    1736        hl_model_2nd_skip_connection_conc\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_34 (TFOpLa (None, 13, 13, 8)    0           hl_model_local_conv_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "hl_model_hidden_layer_all_hl_0  (None, 256)          664064      hl_model_concat[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "hl_model_3rd_skip_connection_co (None, 13, 13, 16)   0           hl_model_deconv_2.1[0][0]        \n",
      "                                                                 tf.compat.v1.squeeze_34[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "hl_model_hidden_layer_all_hl_1  (None, 512)          131584      hl_model_hidden_layer_all_hl_0[0]\n",
      "__________________________________________________________________________________________________\n",
      "hl_model_deconv_3 (Conv2DTransp (None, 17, 17, 4)    1604        hl_model_3rd_skip_connection_conc\n",
      "__________________________________________________________________________________________________\n",
      "hl_model_hidden_layer_all_hl_2  (None, 256)          131328      hl_model_hidden_layer_all_hl_1[0]\n",
      "__________________________________________________________________________________________________\n",
      "hl_model_deconv_4 (Conv2DTransp (None, 17, 17, 1)    5           hl_model_deconv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "hl_model_landing_preproc_layer_ (None, 128)          32896       hl_model_hidden_layer_all_hl_2[0]\n",
      "__________________________________________________________________________________________________\n",
      "hl_model_deconv_flatten (Flatte (None, 289)          0           hl_model_deconv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "hl_model_landing_layer_hl (Dens (None, 1)            129         hl_model_landing_preproc_layer_hl\n",
      "__________________________________________________________________________________________________\n",
      "hl_model_concat_final (Concaten (None, 290)          0           hl_model_deconv_flatten[0][0]    \n",
      "                                                                 hl_model_landing_layer_hl[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 1,757,034\n",
      "Trainable params: 1,757,034\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def lrelu(inputs):\n",
    "    lrelu = LeakyReLU()(inputs)\n",
    "    bn = BatchNormalization()(lrelu)\n",
    "    return bn\n",
    "\n",
    "conv_layers = 2\n",
    "mb = 25\n",
    "current_mb = 15\n",
    "hidden_layer_size = 256\n",
    "name = 'hl_model_'\n",
    "lm = np.random.rand(17,17,4)\n",
    "gm = np.random.rand(21,21,4)\n",
    "states_proc = np.array(current_mb/mb)\n",
    "\n",
    "\n",
    "def build_hl_model(local_map, global_map, states_proc): #local:17,17,4; global:21:21,4\n",
    "    \n",
    "    # local map processing layers\n",
    "#     for k in range(conv_layers):\n",
    "    local_map_input = tf.keras.layers.Input(shape=local_map.shape)\n",
    "    global_map_input = tf.keras.layers.Input(shape=global_map.shape)\n",
    "    states_proc_input = tf.keras.layers.Input(shape=states_proc.shape)\n",
    "    \n",
    "    local_map_1 = tf.keras.layers.Conv2D(4, 3, activation='elu',\n",
    "                       strides=(1, 1),\n",
    "                       name=name + 'local_conv_' + str(0 + 1))(local_map_input) #out:(None, 1, 15, 15, 4) 1156->\n",
    "    local_map_2 = tf.keras.layers.Conv2D(8, 3, activation='elu',\n",
    "                       strides=(1, 1),\n",
    "                       name=name + 'local_conv_' + str(1 + 1))(local_map_1) #out:(None, 1, 13, 13, 8)\n",
    "    local_map_3 = tf.keras.layers.Conv2D(16, 3, activation='elu',\n",
    "                       strides=(1, 1),\n",
    "                       name=name + 'local_conv_' + str(2 + 1))(local_map_2) #out:(None, 1, 11, 11, 16)\n",
    "    local_map_4 = tf.keras.layers.Conv2D(16, 3, activation='elu',\n",
    "                       strides=(1, 1),\n",
    "                       name=name + 'local_conv_' + str(3 + 1))(local_map_3) #out:(None, 1, 9, 9, 16)\n",
    "    flatten_local = tf.keras.layers.Flatten(name=name + 'local_flatten')(local_map_4)\n",
    "    \n",
    "    # global map processing layers\n",
    "\n",
    "    global_map_1 = tf.keras.layers.Conv2D(4, 5, activation='elu',\n",
    "                       strides=(1, 1),\n",
    "                       name=name + 'global_conv_' + str(0 + 1))(global_map_input) #out:17\n",
    "    global_map_2 = tf.keras.layers.Conv2D(8, 5, activation='elu',\n",
    "                       strides=(1, 1),\n",
    "                       name=name + 'global_map_' + str(1 + 1))(global_map_1) #out:13\n",
    "    global_map_3 = tf.keras.layers.Conv2D(16, 5, activation='elu',\n",
    "                       strides=(1, 1),\n",
    "                       name=name + 'global_map_' + str(2 + 1))(global_map_2)#out:9\n",
    "\n",
    "    flatten_global = tf.keras.layers.Flatten(name=name + 'global_flatten')(global_map_3)\n",
    "    \n",
    "    print(flatten_local.shape, flatten_global.shape)\n",
    "    \n",
    "    flatten_map = tf.keras.layers.Concatenate(name=name + 'concat_flatten')([flatten_global, flatten_local])\n",
    "    \n",
    "    layer = tf.keras.layers.Concatenate(name=name + 'concat')([flatten_map, states_proc_input])\n",
    "    \n",
    "    layer_1 = tf.keras.layers.Dense(256, activation='elu', name=name + 'hidden_layer_all_hl_' + str(0))(\n",
    "                layer)\n",
    "    layer_2 = tf.keras.layers.Dense(512, activation='elu', name=name + 'hidden_layer_all_hl_' + str(1))(\n",
    "                layer_1)\n",
    "    layer_3 = tf.keras.layers.Dense(256, activation='elu', name=name + 'hidden_layer_all_hl_' + str(2))(\n",
    "                layer_2)\n",
    "\n",
    "    output = tf.keras.layers.Dense(units=300, activation='linear', name=name + 'last_dense_layer_hl')(\n",
    "        layer)\n",
    "    \n",
    "    reshape = tf.keras.layers.Reshape((5,5,12), name=name + 'last_dense_layer')(output)\n",
    "\n",
    "    \n",
    "    landing = tf.keras.layers.Dense(units=128, activation='elu', name=name + 'landing_preproc_layer_hl')(\n",
    "        layer_3)\n",
    "    landing = tf.keras.layers.Dense(units=1, activation='elu', name=name + 'landing_layer_hl')(landing)\n",
    "    \n",
    "    # deconvolutional part aiming at 17x17 \n",
    "    deconv_1 = tf.keras.layers.Conv2DTranspose(filters=16, kernel_size=5, activation='elu', name=name + 'deconv_' + str(1))(reshape)\n",
    "    skip_1 = tf.keras.layers.Concatenate(name=name + '1st_skip_connection_concat', axis=3)([deconv_1, tf.squeeze(local_map_4, axis=1)])\n",
    "    deconv_2 = tf.keras.layers.Conv2DTranspose(filters=8, kernel_size=3, activation='elu', name=name + 'deconv_' + str(2))(skip_1)\n",
    "    skip_2 = tf.keras.layers.Concatenate(name=name + '2nd_skip_connection_concat', axis=3)([deconv_2, tf.squeeze(local_map_3, axis=1)])\n",
    "    deconv_2_1 = tf.keras.layers.Conv2DTranspose(filters=8, kernel_size=3, activation='elu', name=name + 'deconv_' + str(2.1))(skip_2)\n",
    "    skip_3 = tf.keras.layers.Concatenate(name=name + '3rd_skip_connection_concat', axis=3)([deconv_2_1, tf.squeeze(local_map_2, axis=1)])\n",
    "    deconv_3 = tf.keras.layers.Conv2DTranspose(filters=4, kernel_size=5, activation='elu', name=name + 'deconv_' + str(3))(skip_3)\n",
    "    deconv_4 = tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=1, activation='elu', name=name + 'deconv_' + str(4))(deconv_3)\n",
    "\n",
    "    flatten_deconv = tf.keras.layers.Flatten(name=name + 'deconv_flatten')(deconv_4)\n",
    "    concat_final = tf.keras.layers.Concatenate(name=name + 'concat_final')([flatten_deconv, landing])\n",
    "    \n",
    "    return tf.keras.Model(inputs=[local_map_input, global_map_input, states_proc_input], outputs=concat_final)\n",
    "    \n",
    "\n",
    "model = build_hl_model(lm[tf.newaxis, ...], gm[tf.newaxis, ...], states_proc[tf.newaxis, ...]) #lm, gm, states_proc)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# model.build()\n",
    "model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8114088c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[[0 1 2 3 4]\n",
      " [5 6 7 8 9]]\n",
      "tf.Tensor(\n",
      "[[0 1 2 3 4]\n",
      " [5 6 7 8 9]], shape=(2, 5), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(10)\n",
    "print(a)\n",
    "a = a.reshape(2,5)\n",
    "print(a)\n",
    "a = tf.keras.layers.Flatten()(tf.convert_to_tensor(a))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c222e67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32) tf.Tensor(2, shape=(), dtype=int32) tf.Tensor(3, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a, b, c = tf.stop_gradient([1,2,3])\n",
    "print( a,b,c\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c581f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267dc038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58eda6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e46b61a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3c9739e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_map_in = np.zeros((4,5))\n",
    "global_map_in = np.ones_like(local_map_in)\n",
    "scalars_in = 1\n",
    "# local_map_in[0][4]=np.float('nan')\n",
    "if np.any(np.isnan(local_map_in)) or np.any(np.isnan(global_map_in)) or np.any(np.isnan(scalars_in)) :\n",
    "    print(f'###################### Nan in act input: {np.isnan(local_map_in)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8b4b41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01c28737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]], shape=(5, 8), dtype=float32)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "size = (40)\n",
    "p = np.zeros(size)\n",
    "p[1] = 1\n",
    "a = np.random.choice(range(40), size=1, p=p)\n",
    "a = tf.one_hot((1000), depth=size).numpy().reshape(5,8)\n",
    "print(a)\n",
    "a = tf.keras.layers.Flatten()(a)\n",
    "print(a)\n",
    "a = a.numpy().reshape(5,8)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alpine-finger",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Value for attr 'T' of int64 is not in the list of allowed values: bfloat16, half, float, double\n\t; NodeDef: {{node IsNan}}; Op<name=IsNan; signature=x:T -> y:bool; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]> [Op:IsNan]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4fcc265e9114>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlvenv/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mis_nan\u001b[0;34m(x, name)\u001b[0m\n\u001b[1;32m   4789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4790\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4791\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4792\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4793\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlvenv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlvenv/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Value for attr 'T' of int64 is not in the list of allowed values: bfloat16, half, float, double\n\t; NodeDef: {{node IsNan}}; Op<name=IsNan; signature=x:T -> y:bool; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]> [Op:IsNan]"
     ]
    }
   ],
   "source": [
    "b = np.array([1, 1, 0, 0, 1])\n",
    "\n",
    "b = tf.math.is_nan(tf.convert_to_tensor(b))\n",
    "\n",
    "a = tf.reduce_any(b)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "regular-skirt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[[0.85903    0.45615618 0.75352573 0.28616315 0.656314   0.40986627\n",
      "  0.31044914 0.94073707 0.03260706 0.20273256 0.53378992]\n",
      " [0.56615772 0.20992389 0.21193915 0.38760111 0.7934665  0.57851711\n",
      "  0.14808255 0.07390192 0.00809374 0.86135458 0.0260759 ]\n",
      " [0.73361629 0.37659285 0.34437586 0.6400296  0.87902691 0.48436414\n",
      "  0.49118999 0.31552158 0.68295266 0.98499074 0.66384527]\n",
      " [0.65358725 0.91551074 0.35424552 0.92398924 0.2827416  0.77516516\n",
      "  0.79810265 0.21162833 0.80351687 0.90661335 0.50315294]\n",
      " [0.19520098 0.70098219 0.38246709 0.72394498 0.         0.\n",
      "  0.         0.44388019 0.18274414 0.9029086  0.77770016]\n",
      " [0.62226835 0.63678732 0.7381341  0.3879475  0.         0.\n",
      "  0.         0.69032153 0.8001331  0.8663466  0.10392525]\n",
      " [0.61907532 0.12746065 0.40523353 0.20330397 0.         0.\n",
      "  0.         0.71342267 0.3259403  0.99208458 0.24866851]\n",
      " [0.49543152 0.33516277 0.5995586  0.38818935 0.22187303 0.19782512\n",
      "  0.91076292 0.85435479 0.37687985 0.21084955 0.70612536]\n",
      " [0.80627865 0.42170152 0.43714887 0.76846941 0.23046562 0.38785737\n",
      "  0.13959836 0.92770249 0.94806577 0.58370962 0.85580163]\n",
      " [0.6092264  0.94894204 0.47589102 0.00169341 0.54790165 0.17868032\n",
      "  0.97465975 0.90827907 0.45635785 0.52106672 0.24707265]\n",
      " [0.54113419 0.81209233 0.73425428 0.22573739 0.61183313 0.23493544\n",
      "  0.19775216 0.42191449 0.131545   0.23224329 0.16233885]]\n",
      "[0.85903    0.45615616 0.75352573 0.28616315 0.656314   0.40986627\n",
      " 0.31044915 0.94073707 0.03260706 0.20273256 0.53378993 0.5661577\n",
      " 0.2099239  0.21193914 0.3876011  0.7934665  0.57851714 0.14808254\n",
      " 0.07390192 0.00809374 0.8613546  0.0260759  0.7336163  0.37659284\n",
      " 0.34437585 0.6400296  0.8790269  0.48436415 0.49119    0.31552157\n",
      " 0.68295264 0.9849907  0.66384524 0.6535873  0.9155107  0.3542455\n",
      " 0.92398924 0.2827416  0.77516514 0.7981027  0.21162833 0.80351686\n",
      " 0.90661335 0.50315297 0.19520098 0.7009822  0.3824671  0.72394496\n",
      " 0.         0.         0.         0.4438802  0.18274413 0.9029086\n",
      " 0.7777002  0.6222684  0.6367873  0.7381341  0.3879475  0.\n",
      " 0.         0.         0.6903215  0.8001331  0.8663466  0.10392525\n",
      " 0.6190753  0.12746066 0.40523353 0.20330396 0.         0.\n",
      " 0.         0.71342266 0.3259403  0.99208456 0.2486685  0.4954315\n",
      " 0.33516276 0.5995586  0.38818935 0.22187303 0.19782512 0.9107629\n",
      " 0.8543548  0.37687984 0.21084955 0.7061254  0.80627865 0.42170152\n",
      " 0.43714887 0.7684694  0.23046562 0.38785738 0.13959835 0.9277025\n",
      " 0.94806576 0.5837096  0.85580164 0.6092264  0.94894207 0.47589102\n",
      " 0.00169341 0.54790163 0.17868033 0.97465974 0.90827906 0.45635784\n",
      " 0.5210667  0.24707265 0.5411342  0.8120923  0.7342543  0.2257374\n",
      " 0.61183316 0.23493545 0.19775216 0.4219145  0.13154499 0.23224328\n",
      " 0.16233885]\n",
      "[0.01158038 0.00774029 0.01042085 0.00653026 0.0094555  0.00739016\n",
      " 0.00669079 0.01256632 0.00506771 0.00600754 0.00836514 0.00864033\n",
      " 0.0060509  0.00606311 0.00722743 0.01084549 0.00874778 0.00568804\n",
      " 0.00528137 0.004945   0.01160734 0.00503472 0.01021543 0.00714831\n",
      " 0.00692168 0.00930277 0.01181429 0.00796173 0.00801627 0.00672482\n",
      " 0.00971077 0.01313491 0.00952698 0.00942976 0.01225328 0.00699033\n",
      " 0.01235761 0.00650795 0.01064881 0.01089589 0.00606122 0.01095504\n",
      " 0.01214474 0.00811274 0.00596246 0.00988744 0.00719042 0.01011711\n",
      " 0.00490514 0.00490514 0.00490514 0.00764585 0.00588865 0.01209983\n",
      " 0.01067584 0.009139   0.00927266 0.01026168 0.00722994 0.00490514\n",
      " 0.00490514 0.00490514 0.00978259 0.01091804 0.01166542 0.00544233\n",
      " 0.00910987 0.00557194 0.007356   0.00601097 0.00490514 0.00490514\n",
      " 0.00490514 0.01001121 0.00679524 0.01322842 0.00628994 0.00805034\n",
      " 0.0068582  0.0089338  0.00723168 0.00612363 0.00597813 0.01219524\n",
      " 0.01152637 0.00715036 0.0060565  0.00993842 0.01098534 0.00747814\n",
      " 0.00759456 0.01057774 0.00617648 0.00722929 0.00563998 0.01240358\n",
      " 0.01265875 0.00879332 0.01154306 0.00902058 0.01266985 0.00789456\n",
      " 0.00491345 0.00848402 0.00586477 0.01299991 0.01216498 0.00774185\n",
      " 0.00825938 0.00627991 0.0084268  0.01104939 0.01022195 0.00614735\n",
      " 0.00904413 0.00620415 0.00597769 0.00747973 0.00559475 0.00618747\n",
      " 0.00576971]\n"
     ]
    }
   ],
   "source": [
    "sz = 11\n",
    "a = np.random.rand(sz,sz)\n",
    "b = 3\n",
    "c = int((sz-1)/2 - (b-1)/2)\n",
    "print(c)\n",
    "for i in range(b):\n",
    "    for j in range(b):\n",
    "#         a[i+c][j+c]=-math.inf\n",
    "        a[i+c][j+c]=0\n",
    "        \n",
    "        \n",
    "print(a)\n",
    "a = tf.keras.layers.Flatten()(a[tf.newaxis, ...]).numpy()\n",
    "a = np.squeeze(a)\n",
    "print(a)\n",
    "a = scipy.special.softmax(a)\n",
    "print(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "behind-glossary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.76181723 0.44534156 0.66537213\n",
      "  0.99453811 0.92273703 0.91531384 0.87244398 0.63392102 0.79081619\n",
      "  0.2361872  0.07628017 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.57719785 0.85631048 0.6116705\n",
      "  0.42807821 0.44677604 0.9827626  0.10399085 0.15583558 0.0555077\n",
      "  0.87603932 0.79392707 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.47938728 0.49354469 0.3395669\n",
      "  0.34023351 0.90847343 0.50912706 0.35745864 0.1611303  0.85618968\n",
      "  0.78897265 0.80688676 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.75091189 0.4542349  0.42034586\n",
      "  0.25246496 0.55325201 0.39630838 0.56428047 0.83955843 0.41505947\n",
      "  0.35321452 0.77643613 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.80781209 0.96572507 0.1031235\n",
      "  0.16607626 0.1133003  0.60075425 0.67889049 0.7119989  0.61166602\n",
      "  0.40257559 0.98249968 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.128886   0.85509524 0.38092101\n",
      "  0.86349268 0.18777041 0.41608138 0.83462434 0.59686333 0.53574295\n",
      "  0.14993223 0.78348061 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.00144689 0.02666539 0.29448727\n",
      "  0.54532638 0.44243586 0.22955977 0.09887055 0.3744612  0.0962165\n",
      "  0.2638637  0.16449845 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.53589767 0.27044362 0.75674756\n",
      "  0.1002469  0.38229672 0.74343444 0.08376721 0.54327714 0.92371232\n",
      "  0.70493676 0.3854846  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.1048669  0.97565011 0.51579935\n",
      "  0.57320343 0.38599205 0.07692458 0.95576389 0.69605442 0.0114053\n",
      "  0.40998882 0.13584043 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.03996253 0.20200814 0.27017422\n",
      "  0.03397632 0.62943747 0.2380568  0.32712564 0.37708691 0.2787412\n",
      "  0.83068124 0.62599562 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.7239421  0.35693653 0.25707462\n",
      "  0.77940229 0.07464426 0.57406134 0.00579886 0.57196461 0.55900043\n",
      "  0.52349929 0.02712629 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "3\n",
      "[[0.76181723 0.44534156 0.66537213 0.99453811 0.92273703 0.91531384\n",
      "  0.87244398 0.63392102 0.79081619 0.2361872  0.07628017]\n",
      " [0.57719785 0.85631048 0.6116705  0.42807821 0.44677604 0.9827626\n",
      "  0.10399085 0.15583558 0.0555077  0.87603932 0.79392707]\n",
      " [0.47938728 0.49354469 0.3395669  0.34023351 0.90847343 0.50912706\n",
      "  0.35745864 0.1611303  0.85618968 0.78897265 0.80688676]\n",
      " [0.75091189 0.4542349  0.42034586 0.25246496 0.55325201 0.39630838\n",
      "  0.56428047 0.83955843 0.41505947 0.35321452 0.77643613]\n",
      " [0.80781209 0.96572507 0.1031235  0.16607626 0.1133003  0.60075425\n",
      "  0.67889049 0.7119989  0.61166602 0.40257559 0.98249968]\n",
      " [0.128886   0.85509524 0.38092101 0.86349268 0.18777041 0.41608138\n",
      "  0.83462434 0.59686333 0.53574295 0.14993223 0.78348061]\n",
      " [0.00144689 0.02666539 0.29448727 0.54532638 0.44243586 0.22955977\n",
      "  0.09887055 0.3744612  0.0962165  0.2638637  0.16449845]\n",
      " [0.53589767 0.27044362 0.75674756 0.1002469  0.38229672 0.74343444\n",
      "  0.08376721 0.54327714 0.92371232 0.70493676 0.3854846 ]\n",
      " [0.1048669  0.97565011 0.51579935 0.57320343 0.38599205 0.07692458\n",
      "  0.95576389 0.69605442 0.0114053  0.40998882 0.13584043]\n",
      " [0.03996253 0.20200814 0.27017422 0.03397632 0.62943747 0.2380568\n",
      "  0.32712564 0.37708691 0.2787412  0.83068124 0.62599562]\n",
      " [0.7239421  0.35693653 0.25707462 0.77940229 0.07464426 0.57406134\n",
      "  0.00579886 0.57196461 0.55900043 0.52349929 0.02712629]]\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros((17,17))\n",
    "v = np.zeros((11,11))\n",
    "\n",
    "b = np.random.rand(11,11)\n",
    "dv = int((a.shape[0]-b.shape[0])/2)\n",
    "print(dv)\n",
    "for i in range(b.shape[0]):\n",
    "    for j in range(b.shape[1]):\n",
    "        a[i+dv][j+dv]=b[i][j]\n",
    "print(a)\n",
    "# v = np.zeros((11,11,4))\n",
    "print(v)\n",
    "dv = int((a.shape[0]-v.shape[0])/2)\n",
    "print(dv)\n",
    "\n",
    "for i in range(v.shape[0]):\n",
    "    for j in range(v.shape[1]):\n",
    "        v[i][j]=a[i+dv][j+dv] # [3]\n",
    "\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "finished-parks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25904504 0.68717655 0.11512531 0.28208636 0.5846623  0.99661703\n",
      " 0.35522018 0.57994194 0.38497601 0.60231917 0.62376007 0.78852036\n",
      " 0.83376386 0.0993048  0.56225165 0.91185519 0.4895587  0.59208711\n",
      " 0.15581138 0.87751222 0.69861943 0.70174703 0.35580533 0.04777022\n",
      " 0.33299776]\n",
      "[[1 1 0 0 1]\n",
      " [0 1 0 0 1]\n",
      " [1 1 1 0 0]\n",
      " [1 1 1 1 0]\n",
      " [1 0 0 0 0]]\n",
      "[[0 0 1 1 0]\n",
      " [1 0 1 1 0]\n",
      " [0 0 0 1 1]\n",
      " [0 0 0 0 1]\n",
      " [0 1 1 1 1]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "condition [5,5], then [], and else [25] must be broadcastable [Op:SelectV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ff56f6ba3ac4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlvenv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlvenv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7105\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7106\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7107\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: condition [5,5], then [], and else [25] must be broadcastable [Op:SelectV2]"
     ]
    }
   ],
   "source": [
    "a = np.random.rand(5,5)\n",
    "a = a.flatten()\n",
    "print(a)\n",
    "v = np.zeros((5,5,2))\n",
    "v = np.random.randint(0, 2, size=(5,5,2))\n",
    "print(v[..., 0])\n",
    "v = (~(v.astype(bool))).astype(int)\n",
    "print(v[..., 0])\n",
    "\n",
    "a = tf.where(v[..., 0], -np.inf, a)\n",
    "print(a)\n",
    "a = a.reshape(5,5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-chick",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
